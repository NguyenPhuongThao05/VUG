{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5cda5a",
   "metadata": {},
   "source": [
    "# VUG Cross-Domain Recommendation Experiments on Kaggle\n",
    "\n",
    "This notebook runs VUG (Virtual User Generation) cross-domain recommendation experiments on Kaggle platform.\n",
    "\n",
    "## Overview\n",
    "- **VUG_CMF**: Combines VUG with Collective Matrix Factorization  \n",
    "- **VUG_CLFM**: Combines VUG with Cross-domain Learning via Feature Mapping\n",
    "- **VUG_BiTGCF**: Combines VUG with BiTGCF Graph Convolution\n",
    "- **Ablation Studies**: Analyze individual components of VUG model\n",
    "\n",
    "## Notebook Structure\n",
    "1. **Environment Setup** - Install dependencies and setup Kaggle environment\n",
    "2. **Import VUG Code** - Load VUG source code from Kaggle dataset\n",
    "3. **Run Experiments** - Execute VUG models and ablation studies  \n",
    "4. **Results Analysis** - Visualize and compare experimental results\n",
    "5. **Save Results** - Export results for submission or further analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe4762",
   "metadata": {},
   "source": [
    "## 1. Set Up Kaggle Environment\n",
    "\n",
    "First, we'll set up the Kaggle environment, install dependencies, and configure the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7023050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for VUG experiments\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package with error handling\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ Successfully installed {package}\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(f\"‚ùå Failed to install {package}\")\n",
    "\n",
    "# Essential packages for VUG experiments  \n",
    "packages = [\n",
    "    \"recbole>=1.1.1\",\n",
    "    \"torch>=1.9.0\", \n",
    "    \"scipy>=1.7.0\",\n",
    "    \"pandas>=1.3.0\",\n",
    "    \"scikit-learn>=1.0.0\", \n",
    "    \"PyYAML>=5.4.0\",\n",
    "    \"colorlog>=6.4.0\",\n",
    "    \"tqdm>=4.62.0\",\n",
    "    \"matplotlib>=3.4.0\",\n",
    "    \"seaborn>=0.11.0\"\n",
    "]\n",
    "\n",
    "print(\"üì¶ Installing VUG dependencies...\")\n",
    "for package in packages:\n",
    "    install_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle working environment\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "def setup_kaggle_workspace():\n",
    "    \"\"\"Setup workspace for VUG experiments\"\"\"\n",
    "    \n",
    "    # Create working directory\n",
    "    work_dir = Path(\"/kaggle/working/VUG\")\n",
    "    work_dir.mkdir(exist_ok=True)\n",
    "    os.chdir(work_dir)\n",
    "    \n",
    "    # Add to Python path\n",
    "    if str(work_dir) not in sys.path:\n",
    "        sys.path.insert(0, str(work_dir))\n",
    "    \n",
    "    print(f\"üìÅ Working directory: {work_dir}\")\n",
    "    \n",
    "    # Check for VUG dataset in input\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    vug_datasets = list(kaggle_input.glob(\"*vug*\")) + list(kaggle_input.glob(\"*VUG*\"))\n",
    "    \n",
    "    if vug_datasets:\n",
    "        source_path = vug_datasets[0]\n",
    "        print(f\"üìã Found VUG dataset: {source_path}\")\n",
    "        \n",
    "        # Copy VUG source code\n",
    "        if (source_path / \"recbole_cdr\").exists():\n",
    "            shutil.copytree(source_path / \"recbole_cdr\", work_dir / \"recbole_cdr\", dirs_exist_ok=True)\n",
    "            print(\"‚úÖ VUG source code copied\")\n",
    "            \n",
    "        # Copy other files\n",
    "        for pattern in [\"*.py\", \"*.yaml\", \"*.txt\"]:\n",
    "            for file in source_path.glob(pattern):\n",
    "                shutil.copy2(file, work_dir)\n",
    "                print(f\"üìÑ Copied {file.name}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No VUG dataset found in /kaggle/input\")\n",
    "        print(\"üí° Please add VUG source code as a Kaggle dataset\")\n",
    "    \n",
    "    return work_dir\n",
    "\n",
    "# Setup workspace\n",
    "workspace = setup_kaggle_workspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd990cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability and optimize for Kaggle\n",
    "def check_and_optimize_gpu():\n",
    "    \"\"\"Check GPU and apply optimizations\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"üéÆ GPU Available: {gpu_name}\")\n",
    "            print(f\"üíæ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "            \n",
    "            # Clear GPU memory\n",
    "            torch.cuda.empty_cache()\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No GPU available - using CPU\")\n",
    "            return False\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  PyTorch not available\")\n",
    "        return False\n",
    "\n",
    "# Environment optimizations\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Check GPU\n",
    "has_gpu = check_and_optimize_gpu()\n",
    "\n",
    "# Memory cleanup\n",
    "gc.collect()\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be523ba",
   "metadata": {},
   "source": [
    "## 2. Import and Verify VUG Code\n",
    "\n",
    "Import the VUG models and verify they're working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b982702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VUG models and verify installation\n",
    "def verify_vug_installation():\n",
    "    \"\"\"Verify that VUG models can be imported\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Import RecBole CDR\n",
    "        from recbole_cdr.quick_start import run_recbole_cdr\n",
    "        print(\"‚úÖ RecBole CDR imported successfully\")\n",
    "        \n",
    "        # Import VUG models\n",
    "        from recbole_cdr.model.cross_domain_recommender.vug_cmf import VUG_CMF\n",
    "        from recbole_cdr.model.cross_domain_recommender.vug_clfm import VUG_CLFM  \n",
    "        from recbole_cdr.model.cross_domain_recommender.vug_bitgcf import VUG_BiTGCF\n",
    "        from recbole_cdr.model.cross_domain_recommender.vug import VUG\n",
    "        \n",
    "        print(\"‚úÖ VUG models imported successfully:\")\n",
    "        print(\"   - VUG_CMF (VUG + Collective Matrix Factorization)\")\n",
    "        print(\"   - VUG_CLFM (VUG + Cross-domain Learning via Feature Mapping)\")\n",
    "        print(\"   - VUG_BiTGCF (VUG + BiTGCF Graph Convolution)\")\n",
    "        print(\"   - VUG (Base model for ablation studies)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Import failed: {e}\")\n",
    "        print(\"üí° Make sure VUG source code is uploaded as a Kaggle dataset\")\n",
    "        return False\n",
    "\n",
    "# Verify installation\n",
    "installation_ok = verify_vug_installation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available datasets and configurations\n",
    "def check_datasets_and_configs():\n",
    "    \"\"\"Check available datasets and configuration files\"\"\"\n",
    "    \n",
    "    # Check datasets\n",
    "    dataset_dir = Path(\"recbole_cdr/dataset\")\n",
    "    if dataset_dir.exists():\n",
    "        datasets = [d.name for d in dataset_dir.iterdir() if d.is_dir()]\n",
    "        print(f\"üìä Available datasets: {datasets}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No datasets found\")\n",
    "    \n",
    "    # Check model configs\n",
    "    config_dir = Path(\"recbole_cdr/properties/model\")\n",
    "    if config_dir.exists():\n",
    "        configs = [f.stem for f in config_dir.glob(\"*.yaml\")]\n",
    "        print(f\"‚öôÔ∏è  Available model configs: {configs}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No model configs found\")\n",
    "    \n",
    "    # Check dataset configs\n",
    "    dataset_config_dir = Path(\"recbole_cdr/properties/dataset\") \n",
    "    if dataset_config_dir.exists():\n",
    "        dataset_configs = [f.stem for f in dataset_config_dir.glob(\"*.yaml\")]\n",
    "        print(f\"üìã Available dataset configs: {dataset_configs}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No dataset configs found\")\n",
    "\n",
    "check_datasets_and_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d127d46",
   "metadata": {},
   "source": [
    "## 3. Run VUG Model Experiments\n",
    "\n",
    "Run the three VUG combination models with Kaggle optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Experiment Runner Class\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class KaggleVUGRunner:\n",
    "    \"\"\"Optimized VUG experiment runner for Kaggle\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results_dir = Path(\"/kaggle/working/results\")\n",
    "        self.results_dir.mkdir(exist_ok=True)\n",
    "        self.start_time = time.time()\n",
    "        self.max_runtime = 8.5 * 3600  # 8.5 hours\n",
    "        \n",
    "    def check_time(self):\n",
    "        \"\"\"Check remaining time\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        remaining = (self.max_runtime - elapsed) / 3600\n",
    "        print(f\"‚è±Ô∏è  Time remaining: {remaining:.1f} hours\")\n",
    "        return remaining > 0.5  # At least 30 minutes\n",
    "    \n",
    "    def kaggle_config(self):\n",
    "        \"\"\"Kaggle-optimized configuration\"\"\"\n",
    "        return {\n",
    "            'train_epochs': ['BOTH:30', 'TARGET:15'],  # Reduced for Kaggle\n",
    "            'embedding_size': 32,  # Smaller for faster training\n",
    "            'train_batch_size': 512,\n",
    "            'eval_batch_size': 1024,\n",
    "            'eval_step': 5,\n",
    "            'stopping_step': 5,\n",
    "            'learning_rate': 0.001,\n",
    "            'n_layers': 1,  # For BiTGCF\n",
    "        }\n",
    "    \n",
    "    def run_experiment(self, model_name, dataset='Amazon'):\n",
    "        \"\"\"Run single experiment\"\"\"\n",
    "        if not self.check_time():\n",
    "            return None\n",
    "            \n",
    "        print(f\"üöÄ Running {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            from recbole_cdr.quick_start import run_recbole_cdr\n",
    "            \n",
    "            # Configuration files\n",
    "            dataset_config = f'./recbole_cdr/properties/dataset/{dataset}.yaml'\n",
    "            model_config = f'./recbole_cdr/properties/model/{model_name}.yaml'\n",
    "            \n",
    "            # Run with Kaggle config\n",
    "            start = time.time()\n",
    "            result = run_recbole_cdr(\n",
    "                model=model_name.replace('_', '') if '_' in model_name else model_name,\n",
    "                config_file_list=[dataset_config, model_config],\n",
    "                config_dict=self.kaggle_config()\n",
    "            )\n",
    "            runtime = time.time() - start\n",
    "            \n",
    "            # Extract results\n",
    "            results = {\n",
    "                'model': model_name,\n",
    "                'dataset': dataset, \n",
    "                'runtime_minutes': round(runtime/60, 2),\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'metrics': {}\n",
    "            }\n",
    "            \n",
    "            if 'test_result' in result and 'rec' in result['test_result']:\n",
    "                test_metrics = result['test_result']['rec']\n",
    "                for metric in ['HR@10', 'HR@20', 'NDCG@10', 'NDCG@20']:\n",
    "                    if metric in test_metrics:\n",
    "                        results['metrics'][metric] = float(test_metrics[metric])\n",
    "            \n",
    "            # Save results\n",
    "            result_file = self.results_dir / f\"{model_name}_{dataset}_results.json\"\n",
    "            with open(result_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ {model_name} completed in {runtime/60:.1f} minutes\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {model_name} failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize runner\n",
    "runner = KaggleVUGRunner()\n",
    "print(\"üéØ Kaggle VUG Runner initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run VUG combination models\n",
    "vug_models = ['VUG_CMF', 'VUG_CLFM', 'VUG_BiTGCF']\n",
    "vug_results = {}\n",
    "\n",
    "print(\"üéØ Running VUG Combination Models\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for model in vug_models:\n",
    "    if runner.check_time():\n",
    "        result = runner.run_experiment(model, 'Amazon')\n",
    "        if result:\n",
    "            vug_results[model] = result\n",
    "            \n",
    "            # Display results\n",
    "            print(f\"\\nüìä {model} Results:\")\n",
    "            for metric, value in result['metrics'].items():\n",
    "                print(f\"   {metric}: {value:.4f}\")\n",
    "        \n",
    "        # Memory cleanup\n",
    "        gc.collect()\n",
    "        if 'torch' in sys.modules:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(f\"‚è∞ Skipping {model} due to time limit\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ Completed {len(vug_results)} out of {len(vug_models)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7e817",
   "metadata": {},
   "source": [
    "## 4. Run Ablation Studies (Optional)\n",
    "\n",
    "If time permits, run ablation studies to analyze VUG components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f88341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ablation studies if time permits\n",
    "ablation_configs = {\n",
    "    'VUG_wo_constrain': {'gen_weight': 0.0},\n",
    "    'VUG_wo_super': {'gen_weight': 0.0, 'enhance_weight': 0.0},\n",
    "    'VUG_wo_user_attn': {'user_weight_attn': 0.0}, \n",
    "    'VUG_wo_item_attn': {'user_weight_attn': 1.0},\n",
    "    'VUG_full': {}\n",
    "}\n",
    "\n",
    "ablation_results = {}\n",
    "\n",
    "if runner.check_time() and len(vug_results) > 0:\n",
    "    print(\"üß™ Running Ablation Studies\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for variant, config_updates in ablation_configs.items():\n",
    "        if not runner.check_time():\n",
    "            print(\"‚è∞ Time limit reached, stopping ablation studies\")\n",
    "            break\n",
    "            \n",
    "        print(f\"\\nüî¨ Running {variant}...\")\n",
    "        \n",
    "        try:\n",
    "            from recbole_cdr.quick_start import run_recbole_cdr\n",
    "            \n",
    "            # Merge configs\n",
    "            full_config = runner.kaggle_config()\n",
    "            full_config.update(config_updates)\n",
    "            \n",
    "            # Use base VUG model with modified config\n",
    "            start = time.time()\n",
    "            result = run_recbole_cdr(\n",
    "                model='VUG',\n",
    "                config_file_list=['./recbole_cdr/properties/dataset/Amazon.yaml',\n",
    "                                './recbole_cdr/properties/model/VUG.yaml'],\n",
    "                config_dict=full_config\n",
    "            )\n",
    "            runtime = time.time() - start\n",
    "            \n",
    "            # Extract results\n",
    "            variant_result = {\n",
    "                'variant': variant,\n",
    "                'runtime_minutes': round(runtime/60, 2),\n",
    "                'metrics': {}\n",
    "            }\n",
    "            \n",
    "            if 'test_result' in result and 'rec' in result['test_result']:\n",
    "                test_metrics = result['test_result']['rec']\n",
    "                for metric in ['HR@10', 'HR@20', 'NDCG@10', 'NDCG@20']:\n",
    "                    if metric in test_metrics:\n",
    "                        variant_result['metrics'][metric] = float(test_metrics[metric])\n",
    "            \n",
    "            ablation_results[variant] = variant_result\n",
    "            \n",
    "            print(f\"‚úÖ {variant} completed\")\n",
    "            for metric, value in variant_result['metrics'].items():\n",
    "                print(f\"   {metric}: {value:.4f}\")\n",
    "                \n",
    "            # Cleanup\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå {variant} failed: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping ablation studies (insufficient time or no baseline results)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d148e79",
   "metadata": {},
   "source": [
    "## 5. Visualize and Analyze Results\n",
    "\n",
    "Create visualizations and comparisons of the experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a915cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results visualization and comparison tables\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def create_results_table():\n",
    "    \"\"\"Create comprehensive results table\"\"\"\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Add VUG model results\n",
    "    for model, result in vug_results.items():\n",
    "        row = {'Model': model, 'Type': 'VUG_Combination'}\n",
    "        row.update(result['metrics'])\n",
    "        row['Runtime_min'] = result['runtime_minutes']\n",
    "        all_results.append(row)\n",
    "    \n",
    "    # Add ablation results\n",
    "    for variant, result in ablation_results.items():\n",
    "        row = {'Model': variant, 'Type': 'Ablation'}\n",
    "        row.update(result['metrics'])  \n",
    "        row['Runtime_min'] = result['runtime_minutes']\n",
    "        all_results.append(row)\n",
    "    \n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        return df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Create and display results table\n",
    "results_df = create_results_table()\n",
    "\n",
    "if results_df is not None:\n",
    "    print(\"üìä Experimental Results Summary\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display formatted table\n",
    "    pd.set_option('display.precision', 4)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = runner.results_dir / \"experiment_results.csv\"\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nüíæ Results saved to: {csv_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af58b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "if results_df is not None and len(results_df) > 1:\n",
    "    \n",
    "    # Set up plotting\n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('VUG Experiments Results Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Define metrics to plot\n",
    "    metrics = ['HR@10', 'HR@20', 'NDCG@10', 'NDCG@20']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i//2, i%2]\n",
    "        \n",
    "        if metric in results_df.columns:\n",
    "            # Create bar plot\n",
    "            sns.barplot(data=results_df, x='Model', y=metric, hue='Type', ax=ax)\n",
    "            ax.set_title(f'{metric} Comparison', fontweight='bold')\n",
    "            ax.set_xlabel('Model')\n",
    "            ax.set_ylabel(metric)\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for container in ax.containers:\n",
    "                ax.bar_label(container, fmt='%.3f', fontsize=8)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'{metric}\\nNot Available', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{metric} - No Data')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(runner.results_dir / 'results_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìà Visualization created and saved\")\n",
    "else:\n",
    "    print(\"üìä Insufficient data for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0f39d5",
   "metadata": {},
   "source": [
    "## 6. Save and Export Results\n",
    "\n",
    "Package all results for download or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39470877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results package\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "def create_results_package():\n",
    "    \"\"\"Package all results for download\"\"\"\n",
    "    \n",
    "    # Create summary report\n",
    "    report_file = runner.results_dir / \"experiment_report.txt\"\n",
    "    \n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"VUG Cross-Domain Recommendation Experiments\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        f.write(f\"Experiment Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Platform: Kaggle\\n\")\n",
    "        f.write(f\"Total Runtime: {(time.time() - runner.start_time)/3600:.2f} hours\\n\\n\")\n",
    "        \n",
    "        # VUG Models Results\n",
    "        f.write(\"VUG Combination Models:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        for model, result in vug_results.items():\n",
    "            f.write(f\"\\n{model}:\\n\")\n",
    "            f.write(f\"  Runtime: {result['runtime_minutes']:.1f} minutes\\n\")\n",
    "            for metric, value in result['metrics'].items():\n",
    "                f.write(f\"  {metric}: {value:.4f}\\n\")\n",
    "        \n",
    "        # Ablation Results  \n",
    "        if ablation_results:\n",
    "            f.write(\"\\n\\nAblation Study Results:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            for variant, result in ablation_results.items():\n",
    "                f.write(f\"\\n{variant}:\\n\")\n",
    "                f.write(f\"  Runtime: {result['runtime_minutes']:.1f} minutes\\n\")\n",
    "                for metric, value in result['metrics'].items():\n",
    "                    f.write(f\"  {metric}: {value:.4f}\\n\")\n",
    "        \n",
    "        # Best Results Summary\n",
    "        if results_df is not None:\n",
    "            f.write(\"\\n\\nBest Results Summary:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            for metric in ['HR@10', 'NDCG@10']:\n",
    "                if metric in results_df.columns:\n",
    "                    best_idx = results_df[metric].idxmax()\n",
    "                    best_model = results_df.loc[best_idx, 'Model']\n",
    "                    best_value = results_df.loc[best_idx, metric]\n",
    "                    f.write(f\"Best {metric}: {best_model} ({best_value:.4f})\\n\")\n",
    "    \n",
    "    # Create zip package\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    zip_path = Path(f\"/kaggle/working/VUG_Results_{timestamp}.zip\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        # Add all result files\n",
    "        for file in runner.results_dir.glob(\"*\"):\n",
    "            if file.is_file():\n",
    "                zipf.write(file, file.name)\n",
    "        \n",
    "        # Add report\n",
    "        zipf.write(report_file, \"experiment_report.txt\")\n",
    "    \n",
    "    return zip_path, report_file\n",
    "\n",
    "# Create results package\n",
    "if vug_results or ablation_results:\n",
    "    zip_path, report_path = create_results_package()\n",
    "    \n",
    "    print(\"üì¶ Results Package Created\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üìÅ Zip file: {zip_path}\")\n",
    "    print(f\"üìÑ Report: {report_path}\")\n",
    "    print(f\"üìä Results directory: {runner.results_dir}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nüìã Experiment Summary:\")\n",
    "    print(f\"   VUG Models completed: {len(vug_results)}\")\n",
    "    print(f\"   Ablation studies completed: {len(ablation_results)}\")\n",
    "    print(f\"   Total runtime: {(time.time() - runner.start_time)/3600:.2f} hours\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ee2b8",
   "metadata": {},
   "source": [
    "## üéØ Instructions for Running on Kaggle\n",
    "\n",
    "### Step-by-step process:\n",
    "\n",
    "#### 1. **Create Kaggle Dataset**\n",
    "   - Zip your entire VUG project folder (including `recbole_cdr/`, `*.py`, `*.yaml`)\n",
    "   - Upload to Kaggle as a new dataset with title \"VUG Cross-Domain Recommendation\"\n",
    "   - Make it public or private as needed\n",
    "\n",
    "#### 2. **Create New Kaggle Notebook**\n",
    "   - Start a new Kaggle notebook\n",
    "   - Enable GPU accelerator (recommended)\n",
    "   - Add your VUG dataset to the notebook inputs\n",
    "\n",
    "#### 3. **Copy This Notebook**\n",
    "   - Copy all cells from this notebook to your Kaggle notebook\n",
    "   - Run cells sequentially from top to bottom\n",
    "\n",
    "#### 4. **Monitor Progress**\n",
    "   - Check time remaining and adjust experiments accordingly\n",
    "   - Results are automatically saved to `/kaggle/working/results/`\n",
    "   - Download the final zip file with all results\n",
    "\n",
    "#### 5. **Expected Runtime**\n",
    "   - VUG_CMF: ~30-45 minutes  \n",
    "   - VUG_CLFM: ~30-45 minutes\n",
    "   - VUG_BiTGCF: ~45-60 minutes  \n",
    "   - Ablation studies: ~20-30 minutes each\n",
    "\n",
    "### üí° **Tips for Success:**\n",
    "- Use GPU acceleration for faster training\n",
    "- Reduce epochs if running out of time\n",
    "- Monitor memory usage with large datasets\n",
    "- Save intermediate results frequently\n",
    "\n",
    "---\n",
    "**Happy experimenting! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
